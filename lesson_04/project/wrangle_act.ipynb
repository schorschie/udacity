{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"We rate dogs\" data wrangling project\n",
    "\n",
    "1. The WeRateDogs Twitter archive. I am giving this file to you, so imagine it as a file on hand. Download this file manually by clicking the following link: [```twitter_archive_enhanced.csv```](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/59a4e958_twitter-archive-enhanced/twitter-archive-enhanced.csv)\n",
    "\n",
    "1. The tweet image predictions, i.e., what breed of dog (or other object, animal, etc.) is present in each tweet according to a neural network. This file (```image_predictions.tsv```) is hosted on Udacity's servers and should be downloaded programmatically using the Requests library and the following URL: https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\n",
    "\n",
    "1. Each tweet's *retweet count* and *favorite (\"like\") count* at minimum, and any additional data you find interesting. Using the tweet IDs in the WeRateDogs Twitter archive, query the Twitter API for each tweet's JSON data using Python's [Tweepy](http://www.tweepy.org/) library and store each tweet's entire set of JSON data in a file called ```tweet_json.txt``` file. Each tweet's JSON data should be written to its own line. Then read this .txt file line by line into a pandas DataFrame with (at minimum) tweet ID, retweet count, and favorite count.\n",
    "\n",
    "Note: do not include your Twitter API keys, secrets, and tokens in your project submission.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Data for this Project\n",
    "\n",
    "After gathering each of the above pieces of data, assess them visually and programmatically for quality and tidiness issues. Detect and document at least **eight (8) quality issues** and **two (2) tidiness issues** in your ```wrangle_act.ipynb``` Jupyter Notebook. To meet specifications, the issues that satisfy the Project Motivation (see the Key Points header on the previous page) must be assessed.\n",
    "\n",
    "## Cleaning Data for this Project\n",
    "\n",
    "Clean each of the issues you documented while assessing. Perform this cleaning in ```wrangle_act.ipynb``` as well. The result should be a high quality and tidy master pandas DataFrame (or DataFrames, if appropriate). Again, the issues that satisfy the Project Motivation must be cleaned.\n",
    "\n",
    "## Storing, Analyzing, and Visualizing Data for this Project\n",
    "\n",
    "Store the clean DataFrame(s) in a CSV file with the main one named ```twitter_archive_master.csv```. If additional files exist because multiple tables are required for tidiness, name these files appropriately. Additionally, you may store the cleaned data in a SQLite database (which is to be submitted as well if you do).\n",
    "\n",
    "Analyze and visualize your wrangled data in your ```wrangle_act.ipynb``` Jupyter Notebook. At least three (3) insights and one (1) visualization must be produced.\n",
    "\n",
    "## Reporting for this Project\n",
    "\n",
    "Create a 300-600 word written report called ```mwrangle_report.pdf``` or ```wrangle_report.html``` that briefly describes your wrangling efforts. This is to be framed as an internal document.\n",
    "\n",
    "Create a 250-word-minimum written report called ```act_report.pdf``` or ```act_report.html``` that communicates the insights and displays the visualization(s) produced from your wrangled data. This is to be framed as an external document, like a blog post or magazine article, for example.\n",
    "\n",
    "Both of these documents can be created in separate Jupyter Notebooks using the [Markdown functionality](http://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html) of Jupyter Notebooks, then downloading those notebooks as PDF files or HTML files (see image below). You might prefer to use a word processor like Google Docs or Microsoft Word, however.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather Data\n",
    "\n",
    "> #### From Template:  \n",
    "> * Depending on the source of your data, and what format it's in, the steps in gathering data vary.  \n",
    "> * High-level gathering process: obtaining data (downloading a file from the internet, scraping a web page,  \n",
    ">   querying an API, etc.) and importing that data into your programming environment (e.g., Jupyter Notebook).  \n",
    "\n",
    "\n",
    "Data for this projects originates from 3 sources:\n",
    "1. A `twitter-archive-enhanced.csv` file, provided by Udacity\n",
    "1. A `image-predictions.tsv` file, also provided by udacity, but downloaded with python `requests` function.\n",
    "1. A `tweet_coverage.csv` file, created for this project with a twitter API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_predictions():\n",
    "    \"\"\"Load image-predictions from disk if present, else load it from udacity.\n",
    "    \n",
    "    WARNING: This only works from within the udacity project workspace!\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if  not os.path.exists('image-predictions.tsv'):\n",
    "        r = requests.get(\"https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\",\n",
    "                         stream=True)\n",
    "        tsv = r.raw.read()\n",
    "        with open('image-predictions.tsv', 'wb') as f:\n",
    "            f.write(tsv)\n",
    "            \n",
    "    df_image_predictions = pd.read_csv('image-predictions.tsv', sep='\\t')\n",
    "    \n",
    "    return df_image_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_coverate():\n",
    "    \"\"\"Load tweet_coverage from disk if present, else scrape it from twitter.\"\"\"\n",
    "    \n",
    "    if  os.path.exists('tweet_coverage.csv'):\n",
    "        df_tweet_coverage = pd.read_csv('tweet_coverage.csv')\n",
    "    else:\n",
    "        consumer_key = os.environ.get(\"TWITTER_API\")\n",
    "        consumer_secret = os.environ.get(\"TWITTER_API_SECRET\")\n",
    "        access_token = os.environ.get(\"TWITTER_ACCESS_TOKEN\")\n",
    "        access_secret = os.environ.get(\"TWITTER_ACCESS_TOKEN_SECRET\")\n",
    "\n",
    "        auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "        api = tweepy.API(auth)\n",
    "        retweet_count = []\n",
    "        favorite_count = []\n",
    "        favorited = []\n",
    "        retweeted = []\n",
    "\n",
    "        for index, row in df_twitter_archive.iterrows():\n",
    "            try:\n",
    "                tweet_status = api.get_status(row.tweet_id, tweet_mode='extended')._json\n",
    "                retweet_count.append(tweet_status['retweet_count'])\n",
    "                favorite_count.append(tweet_status['favorite_count'])\n",
    "                favorited.append(tweet_status['favorited'])\n",
    "                retweeted.append(tweet_status['retweeted'])\n",
    "            except:\n",
    "                retweet_count.append(np.nan)\n",
    "                favorite_count.append(np.nan)\n",
    "                favorited.append(np.nan)\n",
    "                retweeted.append(np.nan)\n",
    "\n",
    "            if index % 100 == 0:\n",
    "                print('Index is %d' % (index))\n",
    "        print('ready')\n",
    "        df_tweet_coverage = pd.DataFrame(data = list(zip(df_image_predictions['tweet_id'].values, retweet_count,\n",
    "                                                         favorite_count, favorited, retweeted)),\n",
    "                                         columns=['tweet_id', 'retweet_count', \n",
    "                                                  'favorite_count', 'favorited', 'retweeted'])\n",
    "        df_tweet_coverage.to_csv('tweet_coverage.csv', index=False)        \n",
    "        \n",
    "    return df_tweet_coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twitter_archive = pd.read_csv('twitter-archive-enhanced.csv')\n",
    "df_image_predictions = get_image_predictions()\n",
    "df_tweet_coverage = get_tweet_coverate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asses Data\n",
    "\n",
    "> #### From Template:\n",
    "> * Assess data for:\n",
    ">   * Quality: issues with content. Low quality data is also known as dirty data.\n",
    ">   * Tidiness: issues with structure that prevent easy analysis. Untidy data is also known as messy data.\n",
    ">     Tidy data requirements:\n",
    ">       1. Each variable forms a column.\n",
    ">       1. Each observation forms a row.\n",
    ">       1. Each type of observational unit forms a table.\n",
    "> \n",
    "> * Types of assessment:\n",
    ">   * Visual assessment: scrolling through the data in your preferred software application (Google Sheets, Excel,\n",
    ">     a text editor, etc.).\n",
    ">   * Programmatic assessment: using code to view specific portions and summaries of the data (pandas' `head`, `tail`,\n",
    ">     and `info` methods, for example).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_status_id</th>\n",
       "      <th>retweeted_status_user_id</th>\n",
       "      <th>retweeted_status_timestamp</th>\n",
       "      <th>expanded_urls</th>\n",
       "      <th>rating_numerator</th>\n",
       "      <th>rating_denominator</th>\n",
       "      <th>name</th>\n",
       "      <th>doggo</th>\n",
       "      <th>floofer</th>\n",
       "      <th>pupper</th>\n",
       "      <th>puppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>799308762079035393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-17 17:50:33 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>RT @dog_rates: I WAS SENT THE ACTUAL DOG IN TH...</td>\n",
       "      <td>7.743144e+17</td>\n",
       "      <td>4.196984e+09</td>\n",
       "      <td>2016-09-09 18:31:54 +0000</td>\n",
       "      <td>https://twitter.com/dog_rates/status/774314403...</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>674793399141146624</td>\n",
       "      <td>6.717299e+17</td>\n",
       "      <td>4.196984e+09</td>\n",
       "      <td>2015-12-10 03:30:58 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>I have found another. 13/10 https://t.co/HwroP...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/674793399...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>833722901757046785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-02-20 17:00:04 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Bronte. She's fairly h*ckin aerodynami...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/833722901...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>Bronte</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>761672994376806400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-05 21:19:27 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Ohboyohboyohboyohboyohboyohboyohboyohboyohboyo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/761672994...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>697259378236399616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-10 03:22:44 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Please stop sending in saber-toothed tigers. T...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/697259378...</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>getting</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>684222868335505415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-05 04:00:18 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Someone help the girl is being mugged. Several...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/684222868...</td>\n",
       "      <td>121</td>\n",
       "      <td>110</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>708149363256774660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-11 04:35:39 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Jebberson. He's the reigning hide and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/708149363...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Jebberson</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>734912297295085568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-05-24 01:02:00 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>This is Jax. He's a literal fluffball. Sneaky ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/734912297...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>Jax</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>835152434251116546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-02-24 15:40:31 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>When you're so blinded by your systematic plag...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/835152434...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>670434127938719744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-11-28 02:48:46 +0000</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Meet Hank and Sully. Hank is very proud of the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://twitter.com/dog_rates/status/670434127...</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>Hank</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id  in_reply_to_status_id  in_reply_to_user_id  \\\n",
       "589   799308762079035393                    NaN                  NaN   \n",
       "1885  674793399141146624           6.717299e+17         4.196984e+09   \n",
       "328   833722901757046785                    NaN                  NaN   \n",
       "870   761672994376806400                    NaN                  NaN   \n",
       "1435  697259378236399616                    NaN                  NaN   \n",
       "1635  684222868335505415                    NaN                  NaN   \n",
       "1289  708149363256774660                    NaN                  NaN   \n",
       "1105  734912297295085568                    NaN                  NaN   \n",
       "315   835152434251116546                    NaN                  NaN   \n",
       "2113  670434127938719744                    NaN                  NaN   \n",
       "\n",
       "                      timestamp  \\\n",
       "589   2016-11-17 17:50:33 +0000   \n",
       "1885  2015-12-10 03:30:58 +0000   \n",
       "328   2017-02-20 17:00:04 +0000   \n",
       "870   2016-08-05 21:19:27 +0000   \n",
       "1435  2016-02-10 03:22:44 +0000   \n",
       "1635  2016-01-05 04:00:18 +0000   \n",
       "1289  2016-03-11 04:35:39 +0000   \n",
       "1105  2016-05-24 01:02:00 +0000   \n",
       "315   2017-02-24 15:40:31 +0000   \n",
       "2113  2015-11-28 02:48:46 +0000   \n",
       "\n",
       "                                                 source  \\\n",
       "589   <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1885  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "328   <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "870   <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1435  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1635  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1289  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1105  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "315   <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "2113  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                                   text  retweeted_status_id  \\\n",
       "589   RT @dog_rates: I WAS SENT THE ACTUAL DOG IN TH...         7.743144e+17   \n",
       "1885  I have found another. 13/10 https://t.co/HwroP...                  NaN   \n",
       "328   This is Bronte. She's fairly h*ckin aerodynami...                  NaN   \n",
       "870   Ohboyohboyohboyohboyohboyohboyohboyohboyohboyo...                  NaN   \n",
       "1435  Please stop sending in saber-toothed tigers. T...                  NaN   \n",
       "1635  Someone help the girl is being mugged. Several...                  NaN   \n",
       "1289  This is Jebberson. He's the reigning hide and ...                  NaN   \n",
       "1105  This is Jax. He's a literal fluffball. Sneaky ...                  NaN   \n",
       "315   When you're so blinded by your systematic plag...                  NaN   \n",
       "2113  Meet Hank and Sully. Hank is very proud of the...                  NaN   \n",
       "\n",
       "      retweeted_status_user_id retweeted_status_timestamp  \\\n",
       "589               4.196984e+09  2016-09-09 18:31:54 +0000   \n",
       "1885                       NaN                        NaN   \n",
       "328                        NaN                        NaN   \n",
       "870                        NaN                        NaN   \n",
       "1435                       NaN                        NaN   \n",
       "1635                       NaN                        NaN   \n",
       "1289                       NaN                        NaN   \n",
       "1105                       NaN                        NaN   \n",
       "315                        NaN                        NaN   \n",
       "2113                       NaN                        NaN   \n",
       "\n",
       "                                          expanded_urls  rating_numerator  \\\n",
       "589   https://twitter.com/dog_rates/status/774314403...                14   \n",
       "1885  https://twitter.com/dog_rates/status/674793399...                13   \n",
       "328   https://twitter.com/dog_rates/status/833722901...                13   \n",
       "870   https://twitter.com/dog_rates/status/761672994...                10   \n",
       "1435  https://twitter.com/dog_rates/status/697259378...                 8   \n",
       "1635  https://twitter.com/dog_rates/status/684222868...               121   \n",
       "1289  https://twitter.com/dog_rates/status/708149363...                10   \n",
       "1105  https://twitter.com/dog_rates/status/734912297...                10   \n",
       "315   https://twitter.com/dog_rates/status/835152434...                 0   \n",
       "2113  https://twitter.com/dog_rates/status/670434127...                11   \n",
       "\n",
       "      rating_denominator       name doggo floofer pupper puppo  \n",
       "589                   10       None  None    None   None  None  \n",
       "1885                  10       None  None    None   None  None  \n",
       "328                   10     Bronte  None    None   None  None  \n",
       "870                   10       None  None    None   None  None  \n",
       "1435                  10    getting  None    None   None  None  \n",
       "1635                 110       None  None    None   None  None  \n",
       "1289                  10  Jebberson  None    None   None  None  \n",
       "1105                  10        Jax  None    None   None  None  \n",
       "315                   10       None  None    None   None  None  \n",
       "2113                  10       Hank  None    None   None  None  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_twitter_archive.head()\n",
    "df_twitter_archive.sample(10)\n",
    "#df_twitter_archive.expanded_urls[6]\n",
    "#df_twitter_archive.info()\n",
    "#df_twitter_archive[df_twitter_archive.expanded_urls.isna()]\n",
    "#df_twitter_archive.doggo[0]\n",
    "#df_twitter_archive.loc[0, 'doggo'] = None\n",
    "#df_twitter_archive.name.astype('category')\n",
    "#df_twitter_archive['name']\n",
    "#df_twitter_archive.loc[22, 'text']\n",
    "#df_twitter_archive.puppo.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>jpg_url</th>\n",
       "      <th>img_num</th>\n",
       "      <th>p1</th>\n",
       "      <th>p1_conf</th>\n",
       "      <th>p1_dog</th>\n",
       "      <th>p2</th>\n",
       "      <th>p2_conf</th>\n",
       "      <th>p2_dog</th>\n",
       "      <th>p3</th>\n",
       "      <th>p3_conf</th>\n",
       "      <th>p3_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>760539183865880579</td>\n",
       "      <td>https://pbs.twimg.com/media/Co36VZfWcAEN3R3.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Samoyed</td>\n",
       "      <td>0.988013</td>\n",
       "      <td>True</td>\n",
       "      <td>malamute</td>\n",
       "      <td>0.004518</td>\n",
       "      <td>True</td>\n",
       "      <td>West_Highland_white_terrier</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>692417313023332352</td>\n",
       "      <td>https://pbs.twimg.com/media/CZv13u5WYAA6wQe.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>bison</td>\n",
       "      <td>0.208922</td>\n",
       "      <td>False</td>\n",
       "      <td>mink</td>\n",
       "      <td>0.169945</td>\n",
       "      <td>False</td>\n",
       "      <td>polecat</td>\n",
       "      <td>0.144494</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>666826780179869698</td>\n",
       "      <td>https://pbs.twimg.com/media/CUELa0NUkAAscGC.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Maltese_dog</td>\n",
       "      <td>0.359383</td>\n",
       "      <td>True</td>\n",
       "      <td>teddy</td>\n",
       "      <td>0.148759</td>\n",
       "      <td>False</td>\n",
       "      <td>West_Highland_white_terrier</td>\n",
       "      <td>0.106007</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>888078434458587136</td>\n",
       "      <td>https://pbs.twimg.com/media/DFMWn56WsAAkA7B.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>French_bulldog</td>\n",
       "      <td>0.995026</td>\n",
       "      <td>True</td>\n",
       "      <td>pug</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>True</td>\n",
       "      <td>bull_mastiff</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>762316489655476224</td>\n",
       "      <td>https://pbs.twimg.com/media/CpRKzZKWAAABGh7.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>African_grey</td>\n",
       "      <td>0.270468</td>\n",
       "      <td>False</td>\n",
       "      <td>Madagascar_cat</td>\n",
       "      <td>0.076187</td>\n",
       "      <td>False</td>\n",
       "      <td>television</td>\n",
       "      <td>0.033306</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>670385711116361728</td>\n",
       "      <td>https://pbs.twimg.com/media/CU2wPyWWUAAb1MJ.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>whippet</td>\n",
       "      <td>0.178027</td>\n",
       "      <td>True</td>\n",
       "      <td>Chesapeake_Bay_retriever</td>\n",
       "      <td>0.105969</td>\n",
       "      <td>True</td>\n",
       "      <td>beagle</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>828372645993398273</td>\n",
       "      <td>https://pbs.twimg.com/media/C374hb0WQAAIbQ-.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>malamute</td>\n",
       "      <td>0.663047</td>\n",
       "      <td>True</td>\n",
       "      <td>Eskimo_dog</td>\n",
       "      <td>0.207779</td>\n",
       "      <td>True</td>\n",
       "      <td>Tibetan_mastiff</td>\n",
       "      <td>0.040949</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>666411507551481857</td>\n",
       "      <td>https://pbs.twimg.com/media/CT-RugiWIAELEaq.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>coho</td>\n",
       "      <td>0.404640</td>\n",
       "      <td>False</td>\n",
       "      <td>barracouta</td>\n",
       "      <td>0.271485</td>\n",
       "      <td>False</td>\n",
       "      <td>gar</td>\n",
       "      <td>0.189945</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>885167619883638784</td>\n",
       "      <td>https://pbs.twimg.com/media/DEi_N9qXYAAgEEw.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>malamute</td>\n",
       "      <td>0.812482</td>\n",
       "      <td>True</td>\n",
       "      <td>Siberian_husky</td>\n",
       "      <td>0.071712</td>\n",
       "      <td>True</td>\n",
       "      <td>Eskimo_dog</td>\n",
       "      <td>0.055770</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>708834316713893888</td>\n",
       "      <td>https://pbs.twimg.com/media/CdZI_bpWEAAm1fs.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Eskimo_dog</td>\n",
       "      <td>0.283945</td>\n",
       "      <td>True</td>\n",
       "      <td>giant_panda</td>\n",
       "      <td>0.218252</td>\n",
       "      <td>False</td>\n",
       "      <td>malamute</td>\n",
       "      <td>0.180401</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id                                          jpg_url  \\\n",
       "1356  760539183865880579  https://pbs.twimg.com/media/Co36VZfWcAEN3R3.jpg   \n",
       "811   692417313023332352  https://pbs.twimg.com/media/CZv13u5WYAA6wQe.jpg   \n",
       "48    666826780179869698  https://pbs.twimg.com/media/CUELa0NUkAAscGC.jpg   \n",
       "2054  888078434458587136  https://pbs.twimg.com/media/DFMWn56WsAAkA7B.jpg   \n",
       "1371  762316489655476224  https://pbs.twimg.com/media/CpRKzZKWAAABGh7.jpg   \n",
       "228   670385711116361728  https://pbs.twimg.com/media/CU2wPyWWUAAb1MJ.jpg   \n",
       "1775  828372645993398273  https://pbs.twimg.com/media/C374hb0WQAAIbQ-.jpg   \n",
       "29    666411507551481857  https://pbs.twimg.com/media/CT-RugiWIAELEaq.jpg   \n",
       "2040  885167619883638784  https://pbs.twimg.com/media/DEi_N9qXYAAgEEw.jpg   \n",
       "1003  708834316713893888  https://pbs.twimg.com/media/CdZI_bpWEAAm1fs.jpg   \n",
       "\n",
       "      img_num              p1   p1_conf  p1_dog                        p2  \\\n",
       "1356        1         Samoyed  0.988013    True                  malamute   \n",
       "811         1           bison  0.208922   False                      mink   \n",
       "48          1     Maltese_dog  0.359383    True                     teddy   \n",
       "2054        1  French_bulldog  0.995026    True                       pug   \n",
       "1371        1    African_grey  0.270468   False            Madagascar_cat   \n",
       "228         1         whippet  0.178027    True  Chesapeake_Bay_retriever   \n",
       "1775        1        malamute  0.663047    True                Eskimo_dog   \n",
       "29          1            coho  0.404640   False                barracouta   \n",
       "2040        4        malamute  0.812482    True            Siberian_husky   \n",
       "1003        1      Eskimo_dog  0.283945    True               giant_panda   \n",
       "\n",
       "       p2_conf  p2_dog                           p3   p3_conf  p3_dog  \n",
       "1356  0.004518    True  West_Highland_white_terrier  0.001189    True  \n",
       "811   0.169945   False                      polecat  0.144494   False  \n",
       "48    0.148759   False  West_Highland_white_terrier  0.106007    True  \n",
       "2054  0.000932    True                 bull_mastiff  0.000903    True  \n",
       "1371  0.076187   False                   television  0.033306   False  \n",
       "228   0.105969    True                       beagle  0.078720    True  \n",
       "1775  0.207779    True              Tibetan_mastiff  0.040949    True  \n",
       "29    0.271485   False                          gar  0.189945   False  \n",
       "2040  0.071712    True                   Eskimo_dog  0.055770    True  \n",
       "1003  0.218252   False                     malamute  0.180401    True  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_image_predictions.head()\n",
    "df_image_predictions.sample(10)\n",
    "#df_image_predictions.info()\n",
    "#df_image_predictions.p1.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2075 entries, 0 to 2074\n",
      "Data columns (total 5 columns):\n",
      "tweet_id          2075 non-null int64\n",
      "retweet_count     879 non-null float64\n",
      "favorite_count    879 non-null float64\n",
      "favorited         879 non-null object\n",
      "retweeted         879 non-null object\n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 81.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_tweet_coverage.head()\n",
    "df_tweet_coverage.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues found in the files present:\n",
    "\n",
    "#### Quality\n",
    "\n",
    "1. In `df_twitter_archive` the **None** values in the columns `doggo`, `floofer`, `pupper` and `puppo` are strings.\n",
    "1. In `df_twitter_archive` the name column always containts the word after \"This is ...\", which is not always the dogs name.\n",
    "1. In `df_twitter_archive` the `retweeted_status_id` is float.\n",
    "1. In `df_twitter_archive` the `retweeted_status_user_id` is float.\n",
    "1. In `df_twitter_archive` the `timestamp`  column is of type object.\n",
    "1. In `df_image_predictions` not all predicted dog breeds are actually dog breeds.\n",
    "1. In `df_image_predictions` tweed id 762316489655476224 actaully is a dog, not a parrot (african grey).\n",
    "1. In `df_tweet_coverage` retweet_count and facorite_count are float.\n",
    "1. In `df_tweet_coverage` favorited and retweeted are objects.\n",
    "\n",
    "\n",
    "#### Tidiness\n",
    "\n",
    "1. In `df_twitter_archive` the columns doggo, floofer, pupper and puppo always contain \"None\" or the column name.\n",
    "1. In `df_twitter_archive` the overall rating is not present, only nominator and denominator.\n",
    "1. Data is spread arount three data frames (tables)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data\n",
    "\n",
    "> #### From Template:\n",
    "> * Types of cleaning:\n",
    ">   * Manual (not recommended unless the issues are single occurrences)\n",
    ">   * Programmatic\n",
    "> * The programmatic data cleaning process:\n",
    ">   1. Define: convert our assessments into defined cleaning tasks. These definitions also serve as an instruction\n",
    ">      list so others (or yourself in the future) can look at your work and reproduce it.\n",
    ">   1. Code: convert those definitions to code and run that code.\n",
    ">   1. Test: test your dataset, visually or with code, to make sure your cleaning operations worked.\n",
    "> * Always make copies of the original pieces of data before cleaning!\n",
    "\n",
    "### Define\n",
    "#### Quality\n",
    "\n",
    "1. In `df_twitter_archive` the **None** values in the columns `doggo`, `floofer`, `pupper` and `puppo` are strings.\n",
    "   \n",
    "   **Solution:** Change the column type to Boolean, this will also enhance the tidiness. Since according to [Dogtionary](https://video.udacity-data.com/topher/2017/October/59e04ceb_dogtionary-combined/dogtionary-combined.png) dogs can be \"doggo\" and \"pupper\" at the same time, the columns will not be merged to one categoracal column.\n",
    "1. In `df_twitter_archive` the name column always containts the word after \"This is ...\", which is not always the dogs name.\n",
    "\n",
    "   **Solution:** This can only be dealt with manually. Since the dog's name column containts faulty data I will erase it.\n",
    "1. In `df_twitter_archive` the `retweeted_status_id` is float.\n",
    "\n",
    "   **Solution:** Convert `retweeted_status_id`  column to int64.\n",
    "1. In `df_twitter_archive` the `retweeted_status_user_id` is float.\n",
    "\n",
    "   **Solution:** Convert `retweeted_status_user_id`  column to int64.\n",
    "1. In `df_twitter_archive` the `timestamp` column is of type object.\n",
    "\n",
    "   **Solution:** Convert `timestamp`  column to datetime.\n",
    "1. In `df_image_predictions` not all predicted dog breeds are actually dog breeds.\n",
    "\n",
    "   **Solution:** Erase all rows, that do not contain pictures of dogs, with a confidence `p1_conf` of less than 95%.\n",
    "1. In `df_image_predictions` tweed id 762316489655476224 actaully is a dog, not a parrot (african grey).\n",
    "\n",
    "   **Solution:** Erase all rows, that do not contain dogs (```p1_dog == FALSE```).\n",
    "1. In `df_tweet_coverage` retweet_count and facorite_count are float.\n",
    "\n",
    "   **Solution:** convert retweet_count and favorite_count to `int64`.\n",
    "1. In `df_tweet_coverage` favorited and retweeted are objects.\n",
    "\n",
    "   **Solution:** cast favorited and retweeted to `Bool`. \n",
    "\n",
    "\n",
    "#### Tidiness\n",
    "\n",
    "1. In `df_twitter_archive` the columns doggo, floofer, pupper and puppo always contain \"None\" or the column name.\n",
    "\n",
    "   **Solution:** Already taken care of in Quality section (cast to `Boolean`).\n",
    "1. In `df_twitter_archive` the overall rating is not present, only nominator and denominator.\n",
    "\n",
    "   **Solution:** Calcuate an overall rating and \n",
    "\n",
    "1. Data is spread arount three data frames (tables).\n",
    "\n",
    "   **Solution:** Outer join all data frames with common tweet_id, reassess afterwards.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Reassess (Test) and Iterate\n",
    "\n",
    "* After cleaning, always reassess and iterate on any of the data wrangling steps if necessary.\n",
    "\n",
    "## Store (Optional)\n",
    "\n",
    "* Store data, in a file or database for example, if you need to use it in the future.\n",
    "\n",
    "**Also store the dtypes.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-udacity] *",
   "language": "python",
   "name": "conda-env-.conda-udacity-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
